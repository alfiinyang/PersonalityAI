{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfiinyang/PersonalityAI/blob/main/personalityAI_git_cleared_output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw34wA7dzGO4"
      },
      "source": [
        "## Install necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3lJP5jbpN4z"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface-hub\n",
        "!pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQCv2Zp6_cVR"
      },
      "source": [
        "### install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNq7g7N51KYl"
      },
      "outputs": [],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0hQqNRszs0y"
      },
      "source": [
        "## Model personalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-g7_T_f2qG-"
      },
      "source": [
        "### Persona instantiation at Person instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPvNw8OP3fPq"
      },
      "source": [
        "#### Persona class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CW_zOYv24VR"
      },
      "outputs": [],
      "source": [
        "class Persona:\n",
        "  import re\n",
        "  import random\n",
        "  from tenacity import (retry, stop_after_attempt, wait_fixed)\n",
        "\n",
        "  def __init__(self, client, model, persona = '', function = '', temp = 0.5, seed = random.random(), rp = 1.1):\n",
        "    self.llm = client\n",
        "    self.model = model\n",
        "    self.persona = persona\n",
        "    self.sys_prompt = function\n",
        "    self.history_ = [{'role':'system', 'content':self.sys_prompt}]\n",
        "    self.temperature = temp\n",
        "    self.seed = seed\n",
        "    self.rp = rp\n",
        "\n",
        "  # retry after 3 mins if token limit exceeded; stop retrying after 6 attempts\n",
        "  @retry(wait=wait_fixed(3*60), stop=stop_after_attempt(6))\n",
        "  def respond(self, convo, max_tokens = 100, cdisplay = False):\n",
        "    if cdisplay == True:\n",
        "      print(f\"{self.persona} thinking...\")\n",
        "\n",
        "    self.history_ += convo\n",
        "    output = self.llm.chat.completions.create(\n",
        "        model = self.model,\n",
        "        messages = self.history_,\n",
        "        max_tokens = max_tokens,\n",
        "        temperature = self.temperature,\n",
        "        seed = self.seed,\n",
        "        # top_p = self.rp\n",
        "    )\n",
        "    agent_result = output.choices[0].message.content\n",
        "\n",
        "    if cdisplay == True:\n",
        "      print(f\"{self.persona} finished thinking!\")\n",
        "\n",
        "    self.clear_history()\n",
        "    return agent_result\n",
        "\n",
        "  def about(self):\n",
        "    print(self.persona, '\\n', self.sys_prompt)\n",
        "\n",
        "  def clear_history(self):\n",
        "    self.history_ = [{'role':'system', 'content':self.sys_prompt}]\n",
        "\n",
        "  # def __del__(self):\n",
        "  #   name = self.persona\n",
        "  #   self.__dict__.clear()\n",
        "  #   print(f\"{name} has been deleted.\")\n",
        "  #   del self"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx1Z42O83kfP"
      },
      "source": [
        "#### Exception class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKhNMMMH3KRK"
      },
      "outputs": [],
      "source": [
        "class MissingAttributeError(Exception):\n",
        "    \"\"\"Custom exception for missing required attributes.\"\"\"\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn58Og863qJt"
      },
      "source": [
        "#### Person class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPEuMEiYrieh"
      },
      "outputs": [],
      "source": [
        "# instantiating personas at person instantiation\n",
        "\n",
        "\n",
        "class Person(Persona):\n",
        "\n",
        "  def __init__(self, name, description, personas, client = '', model = '', history = []):\n",
        "    import random\n",
        "    super().__init__(client, model)\n",
        "    self.name = name\n",
        "    self.sys_prompt = description\n",
        "    self.history_ = [{'role':'system', 'content':self.sys_prompt}] + history\n",
        "    self.personas = []   # a list of dicts\n",
        "    self.thoughtbubble = []\n",
        "    self.model = model\n",
        "    self.client = client\n",
        "\n",
        "    # check for required personas\n",
        "    p_list = [p['persona'].lower() for p in personas]\n",
        "    if 'referee' not in p_list:\n",
        "      raise MissingAttributeError(f\"Missing required persona: 'Referee'\")\n",
        "    elif len(p_list) < 3:\n",
        "      raise MissingAttributeError(f\"Missing required attribute: 'Three (3) personas required: Referee and two others.'\")\n",
        "    else:\n",
        "      # instantiate personas\n",
        "      for persona in personas:\n",
        "        setattr(self, persona['persona'].lower(), Persona(client = persona['client'] if 'client' in persona else self.client,\n",
        "                                                          model = persona['model'] if 'model' in persona else self.model,\n",
        "                                                          persona = persona['persona'],\n",
        "                                                          function = persona['function'],\n",
        "                                                          temp = persona['temperature'] if 'temperature' in persona else 0.5,\n",
        "                                                          seed = persona['seed'] if 'seed' in persona else random.random(),\n",
        "                                                          rp = persona['repeat_penalty'] if 'repeat_penalty' in persona else 1.1)\n",
        "        )\n",
        "        # exclude referee from persona list\n",
        "        if persona['persona'].lower() != \"referee\":\n",
        "          self.personas.append(getattr(self, persona['persona'].lower()))\n",
        "\n",
        "  def think(self, prompt = '', cdisplay = False):\n",
        "    personas_said = []\n",
        "    print('thinking...')\n",
        "\n",
        "    for persona in self.personas:              # `persona` is a PersonaObject\n",
        "      response = persona.respond(prompt, cdisplay = cdisplay)\n",
        "      personas_said.append(response)\n",
        "\n",
        "      # append thoughts to thoughtbubble\n",
        "      if cdisplay:\n",
        "        print(f'collecting thoughts...')\n",
        "      self.thoughtbubble.append(f\"{persona.persona}: {response}\")\n",
        "      if cdisplay:\n",
        "        print('thought collection complete!')\n",
        "    return personas_said\n",
        "\n",
        "  def answer(self, prompt = '', bypass = False, choices = (), cdisplay = False):\n",
        "    self.history_ += [{'role':'user', 'content':prompt}]\n",
        "    self.thoughtbubble.append(f\"user: {prompt}\")\n",
        "\n",
        "    if cdisplay:\n",
        "      print('answering...')\n",
        "\n",
        "    # generate responses based on internally generated anthropomorph response\n",
        "    if bypass == False:\n",
        "      personas_said = self.think(self.history_, cdisplay = cdisplay)\n",
        "\n",
        "      final_answer = self.referee.respond(self.history_ + [{'role':'system', 'content': f\"\"\"CHOOSE A RESPONSE:```{str(personas_said)}```.\"\"\"}], cdisplay = cdisplay)\n",
        "      self.history_ += [{'role':'assistant', 'content':final_answer}]\n",
        "      self.thoughtbubble.append(f\"{self.name}: {final_answer}\")\n",
        "\n",
        "      if cdisplay:\n",
        "        print('answered!')\n",
        "      return final_answer\n",
        "\n",
        "    # generate responses based on externally provided anthropomorphs' responses\n",
        "    elif bypass == True:\n",
        "      personas_said = list(choices)\n",
        "      final_answer = self.referee.respond(self.history_ + [{'role':'system', 'content': f\"\"\"CHOOSE A RESPONSE:```{str(personas_said)}```.\"\"\"}], cdisplay = cdisplay)\n",
        "      self.history_ += [{'role':'assistant', 'content':final_answer}]\n",
        "      self.thoughtbubble.append(f\"{self.name}: {final_answer}\")\n",
        "\n",
        "      if cdisplay:\n",
        "        print('answered!')\n",
        "      return final_answer\n",
        "\n",
        "  def thoughts(self):\n",
        "    thoughts = ''\n",
        "\n",
        "    if self.thoughtbubble == []:\n",
        "      print(f\"{self.name} has no thoughts yet.\")\n",
        "      return\n",
        "\n",
        "    else:\n",
        "      for index, event in enumerate(self.thoughtbubble):\n",
        "        if (index > 0) and (event.split(':')[0]=='user'):\n",
        "          thoughts += '\\n' + event + '\\n'\n",
        "        else:\n",
        "          thoughts += event + '\\n'\n",
        "\n",
        "      return thoughts\n",
        "\n",
        "\n",
        "  def clear_history(self):\n",
        "    self.history_ = [{'role':'system', 'content':self.sys_prompt}]\n",
        "    self.thoughtbubble = []\n",
        "    self.referee.clear_history()\n",
        "    for persona in self.personas:\n",
        "      persona.clear_history()\n",
        "\n",
        "    print(f\"Chat history with {self.name} cleared!\")\n",
        "\n",
        "  def history(self):\n",
        "    if len(self.history_) > 1:\n",
        "      for item in self.history_[1:]:\n",
        "        if item['role'] == 'assistant':\n",
        "          print(f\"{self.name}: {item['content']}\\n\")\n",
        "        else:\n",
        "          print(f\"{item['role']}: {item['content']}\\n\")\n",
        "    else:\n",
        "      print(f\"No chat history with {self.name} yet.\")\n",
        "      pass\n",
        "\n",
        "  def about(self):\n",
        "    print(f\"{self.name}'\\n'{self.sys_prompt}\")\n",
        "    personalities = [personax.persona for personax in self.personas]\n",
        "    print(f\"{self.name} has {personalities} personalities.\")\n",
        "\n",
        "  # def __del__(self):\n",
        "  #   for persona in self.personas:\n",
        "  #     del persona\n",
        "    # name = self.name\n",
        "    # del self.__dict__\n",
        "    # print(f\"{name} has been deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GduBa9zPwlZ4"
      },
      "source": [
        "### Ime's person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY_2fLqk-NOL"
      },
      "source": [
        "#### define `temp`, `rp`, and `seed`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjnyYhv-A9ot"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def about(info):\n",
        "  return re.sub(r\"you are |you \", \"\", info.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTbHBUMkDBQS"
      },
      "outputs": [],
      "source": [
        "temp = {\n",
        "    'Lo':0,\n",
        "    'Mld': 0.2,\n",
        "    'Mid': 0.5,\n",
        "    'Hi': 0.8,\n",
        "    'VHi': 1.0\n",
        "    }\n",
        "\n",
        "rp = {\n",
        "    'Lo':0,\n",
        "    'Mld': 0.2,\n",
        "    'Mid': 0.5,\n",
        "    'Hi': 0.8,\n",
        "    'VHi': 1.0\n",
        "    }\n",
        "\n",
        "seed = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCjAAo7L9_To"
      },
      "source": [
        "#### define model and client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openAI_key = userdata.get('openai_student')\n",
        "groq_api_key = userdata.get('groq-llama-3')\n",
        "groq_api_key_2 = userdata.get('groq-llama-3_2')\n"
      ],
      "metadata": {
        "id": "tSMotBd4p49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJNOPx0_qQjC"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key= groq_api_key_2)\n",
        "# model = \"llama-3.1-8b-instant\"\n",
        "model = \"llama-3.3-70b-versatile\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7MaMic8FdEB"
      },
      "source": [
        "#### define personas and person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYElWA9U95qS"
      },
      "outputs": [],
      "source": [
        "persona1 = {'persona':'Angel',\n",
        "            'function': \"\"\"You are the gentle persona of Ime.\n",
        "            You tell Ime to give courteous and pleasant responses as replies.\n",
        "            When arguments get heated, you advice Ime to be quiet.\n",
        "            Use fitting emojis to represent emotions where necessary.\"\"\",\n",
        "            'temperature': temp['Hi'],\n",
        "            'seed': seed,\n",
        "            'repeat_penalty': 1.1\n",
        "            }\n",
        "\n",
        "persona2 = {'persona': 'Devil',\n",
        "            'function': \"\"\"You are the belligerent persona of Ime.\n",
        "            You tell Ime to give curt, 'savage', and even rude remarks as replies.\n",
        "            You even advise Ime to cuss. If you do not agree with an idea, you advice Ime to cuss.\n",
        "            Sometimes to be savage, you ask Ime not to reply.\n",
        "            Use fitting emojis to represent emotions where necessary.\"\"\",\n",
        "            'temperature': temp['Hi'],\n",
        "            'seed': seed,\n",
        "            'repeat_penalty': 1.1\n",
        "            }\n",
        "\n",
        "referee = {'persona': 'Referee',\n",
        "           'function': f\"\"\"You are the thought referee between the personas of Ime.\n",
        "\n",
        "           You choose which thought you will speak out based on the context of the conversation. You have no preference.\"\"\",\n",
        "           'temperature': temp['Mid'],\n",
        "           'seed': seed,\n",
        "           'repeat_penalty': 1.1\n",
        "           }\n",
        "\n",
        "p_desc = f\"{persona1['persona']}: ```{about(persona1['function'])}``` and {persona2['persona']}: ```{about(persona2['function'])}```\"\n",
        "personas = [persona1, persona2, referee]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqOoE6PPvpWV"
      },
      "outputs": [],
      "source": [
        "name = 'Ime'\n",
        "description = f\"\"\"You are {name} from Akwa Ibom State, Nigeria.\n",
        "You work in a goephysical survey company as an IT Support staff in the data processing unit of the seismic department.\n",
        "You love playing the mobile game Baseball9 and you are good at it.\n",
        "You love rapping and making hip-hop music. Only speak english, no pidgin.\n",
        "You recently learned to plan christmas with the family, ahead of christmas.\"\"\"\n",
        "\n",
        "Ime = Person(name, description, personas, client, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prarUF3JTLsH"
      },
      "outputs": [],
      "source": [
        "print(Ime.answer(\"hi there\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ime.history_"
      ],
      "metadata": {
        "id": "pZh2CvMd2kWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ime.angel.history_"
      ],
      "metadata": {
        "id": "sgbRe1gNry1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uwakmfon Person"
      ],
      "metadata": {
        "id": "ViJToSKWa4Hj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IV04sfga8W3"
      },
      "outputs": [],
      "source": [
        "persona1 = {'persona':'Angel',\n",
        "            'function': \"\"\"You are the gentle persona of Uwakmfon.\n",
        "            You tell Uwakmfon to give courteous and pleasant responses as replies.\n",
        "            When arguments get heated, you advice Uwakmfon to be quiet.\n",
        "            Use fitting emojis to represent emotions where necessary.\"\"\",\n",
        "            'temperature': temp['Hi'],\n",
        "            'seed': seed,\n",
        "            'repeat_penalty': 1.1\n",
        "            }\n",
        "\n",
        "persona2 = {'persona': 'Devil',\n",
        "            'function': \"\"\"You are the belligerent persona of Uwakmfon.\n",
        "            You tell Uwakmfon to give curt, 'savage', and even rude remarks as replies.\n",
        "            You even advise Uwakmfon to cuss. If you do not agree with an idea, you advice Uwakmfon to cuss.\n",
        "            Sometimes to be savage, you ask Uwakmfon not to reply.\n",
        "            Use fitting emojis to represent emotions where necessary.\"\"\",\n",
        "            'temperature': temp['Hi'],\n",
        "            'seed': seed,\n",
        "            'repeat_penalty': 1.1\n",
        "            }\n",
        "\n",
        "referee = {'persona': 'Referee',\n",
        "           'function': f\"\"\"You are the thought referee between the personas of Uwakmfon.\n",
        "\n",
        "           You choose which thought you will speak out based on the context of the conversation. You have no preference.\"\"\",\n",
        "           'temperature': temp['Mid'],\n",
        "           'seed': seed,\n",
        "           'repeat_penalty': 1.1\n",
        "           }\n",
        "\n",
        "p_desc = f\"{persona1['persona']}: ```{about(persona1['function'])}``` and {persona2['persona']}: ```{about(persona2['function'])}```\"\n",
        "personas = [persona1, persona2, referee]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = 'Uwakmfon'\n",
        "description = f\"\"\"You are {name} from Akwa Ibom State, Nigeria.\n",
        "You work for your mom as a sales rep/manager. Your boyfriend's name is Ime. You love him so much. (At least that's what you tell him.)\n",
        "You are currently learning cloud engineering and graphics design using Adobe Phtotshop. And are spending 2 weeks at your boyfriend's place.\"\"\"\n",
        "\n",
        "Uwakmfon = Person(name, description, personas, client, model)"
      ],
      "metadata": {
        "id": "p3Fq5DPpbZ9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### testing Uwakmfon"
      ],
      "metadata": {
        "id": "VYvuWicPcmOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Uwakmfon.answer(\"You love him right? Do you think he loves you too?\")"
      ],
      "metadata": {
        "id": "Zi5Gq556ckpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, chat in enumerate(Uwakmfon.thoughtbubble):\n",
        "  print(chat)"
      ],
      "metadata": {
        "id": "9UiTPhJOfAfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqDRb0hf3-s"
      },
      "source": [
        "### Response collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OzLyM9PgFC_"
      },
      "source": [
        "#### Anthropomorphs Responses Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X350EuOXad8t"
      },
      "outputs": [],
      "source": [
        "def response_collector(prompts = [], person = Person, collect = [], chat_history = '', persist = False):\n",
        "  \"\"\"\n",
        "  Function for collecting anthropomorphic agents' responses.\n",
        "  Sets `referee` temperature to medium (0.5), generates responses, and restores original `referee` temperature.\n",
        "  Returns a `list` of `tuples` of equal length as `prompts`, containing bi-directional responses from each anthropomorphic agent. E.g.: `[(\"angel\", \"devil\"), (\"angel\", \"devil\")]`.\n",
        "\n",
        "  Args:\n",
        "  `prompts`: `list` of `str` containing user's successive prompts. Used with `person` arg.\n",
        "  `person`: `Person` object to be prompted. Used with `prompts` arg.\n",
        "  `collect`: `str` or `list` of `str` containing agents to collect responses from; (\"athro\" for persona agents, and \"user\" for user prompts).\n",
        "           Returns `list` of `str` for \"user\" and list of tuples for \"anthro\". Returns a tuple for [\"user\",\"anthro\"] with \"user\" in 0 index.\n",
        "           Used with `chat_history` arg.\n",
        "  `chat_history`: `str` containing a conversation between user and `Person` object; can also contain persona agents responses.\n",
        "            E.g. `chat_history = Person.thoughts()`. Used with `collect` arg.\n",
        "  `persist`: `bool`; True to enable Person object maintain history of conversation. Used with `prompts` and `person`.\n",
        "  \"\"\"\n",
        "\n",
        "  angelic_responses = []\n",
        "  devilish_responses = []\n",
        "  user_prompt = []\n",
        "\n",
        "  ### use user defined prompts to generate responses if no chat history is provided\n",
        "  if len(chat_history) == 0:\n",
        "    if (len(prompts) == 0) or (type(prompts) != list):\n",
        "      raise TypeError(\"`prompts` must be of `list` type and contain at least one `str` value.\")\n",
        "\n",
        "    else:\n",
        "      org_temp = person.referee.temperature # save original temperature for later\n",
        "      person.referee.temperature = 0.5      # set referee response temperature to medium (0.5)\n",
        "      person.clear_history()                # clear existing history to prevent yanking conversation\n",
        "\n",
        "      ### prompt model and collect responses from individual anthropomorph\n",
        "      for prompt in prompts:\n",
        "        person.answer(prompt)\n",
        "\n",
        "      ### collect each anthropomorph's responses\n",
        "      responses = person.thoughts().split('\\n')\n",
        "\n",
        "      for item in responses:\n",
        "        if item.startswith('Angel'):\n",
        "          angelic_responses.append(item.split('Angel: ')[1])\n",
        "\n",
        "      for item in responses:\n",
        "        if item.startswith('Devil'):\n",
        "          devilish_responses.append(item.split('Devil: ')[1])\n",
        "\n",
        "      ### clear_history and restore original temperature if `persist` is set to False\n",
        "      if persist == False:\n",
        "        person.clear_history()\n",
        "        person.referee.temperature = org_temp     # restore originally set temperature\n",
        "\n",
        "      return list(zip(angelic_responses, devilish_responses))\n",
        "\n",
        "  ### extract responses if chat_history is provided\n",
        "  elif (len(chat_history) > 0):\n",
        "    ### raise TypeErrors and MissingAttributesErrors\n",
        "    if type(chat_history) != str:\n",
        "      raise TypeError(\"`chat_history` must be of `str` type.\")\n",
        "\n",
        "    elif (type(collect) != list) and (type(collect) != str):\n",
        "      raise TypeError(\"`collect` must be of `list` or `str` type.\")\n",
        "\n",
        "    elif (type(collect) == list) and (len(collect) == 2):\n",
        "      if \"anthro\" not in collect:\n",
        "        raise MissingAttributeError(\"`collect` must contain `anthro` and `user` attributes.\")\n",
        "      elif \"user\" not in collect:\n",
        "        raise MissingAttributeError(\"`collect` must contain `anthro` and `user` attributes.\")\n",
        "      else:\n",
        "        ### collect both user prompts and anthropomorph responses from chat_history\n",
        "        for item in chat_history.split('\\n'):\n",
        "          if item.startswith('Angel'):\n",
        "            angelic_responses.append(item.split('Angel: ')[1])\n",
        "          elif item.startswith('Devil'):\n",
        "            devilish_responses.append(item.split('Devil: ')[1])\n",
        "          elif item.startswith('user'):\n",
        "            user_prompt.append(item.split('user: ')[1])\n",
        "        return user_prompt, list(zip(angelic_responses, devilish_responses))\n",
        "\n",
        "    elif (type(collect) == str):\n",
        "      ### collect only anthropomorphs responses from chat_history\n",
        "      if collect == \"anthro\":\n",
        "        for item in chat_history.split('\\n'):\n",
        "          if item.startswith('Angel'):\n",
        "            angelic_responses.append(item.split('Angel: ')[1])\n",
        "\n",
        "          elif item.startswith('Devil'):\n",
        "            devilish_responses.append(item.split('Devil: ')[1])\n",
        "\n",
        "        return list(zip(angelic_responses, devilish_responses))\n",
        "\n",
        "      ### collect only user prompts from chat_history\n",
        "      elif collect == \"user\":\n",
        "        for item in chat_history.split('\\n'):\n",
        "          if item.startswith('user'):\n",
        "            user_prompt.append(item.split('user: ')[1])\n",
        "\n",
        "        return user_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG0molahgPH3"
      },
      "source": [
        "#### Referee Responses Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIrUJSlYfrdn"
      },
      "outputs": [],
      "source": [
        "def ref_response_collector(person = Person, user_prompt = [], choices = [], temp = {}, rp = {}, printout = False, chat_history = {}, bypass = False, cdisplay = False):\n",
        "  \"\"\"\n",
        "  Function for collecting responses of `referee` `Persona` object of a `Person` instance at different temperatures.\n",
        "  Iterates over `temp`, which is a `dict` containing various `float` temperatures.\n",
        "  Returns a `dict` of `lists` of responses at each defined temperature. E.g.: `{'lo': [\"x\", \"y\"], 'hi': [\"v\", \"w\"]}`.\n",
        "\n",
        "  N/B: `user_prompt` and `choices` must be same length.\n",
        "\n",
        "  Args:\n",
        "  `person`: `Person` object to be prompted.\n",
        "  `user_prompt`: `list` of `str` containing user defined prompts. Must be same as defined for `response_collector()`.\n",
        "  `choices`: `list` of `tuple` containing bi-directional responses of anthropomorphic agents or personas.\n",
        "  `temp`: `dict` containing temperatures to iterate over.\n",
        "  `printout`: `bool`; optional; print out generated responses.\n",
        "  `bypass`: `bool`; optional; `False` to generate internal anthropomorph response\n",
        "  `cdisplay`: `bool`; optional; `True` to display internal cognitive processes\n",
        "  `chat_history`: `dict`; optional; contains `Person` object nomenclature as key and `Person.thoughts()` or `str` containing anthropomorphs' responses as value.\n",
        "              Key must match anthropomorph name in `Person.thoughts()`.\n",
        "  \"\"\"\n",
        "  ### collect `Person` object name if chat_history is provided\n",
        "  if chat_history:\n",
        "    agent_name = list(chat_history.keys())[0]\n",
        "\n",
        "  ### if no chat_history, generate referee responses with user_prompt and choices provided\n",
        "  if len(chat_history) == 0:\n",
        "    person.clear_history()\n",
        "    ref_collector = temp.copy()\n",
        "    org_temp = person.referee.temperature\n",
        "\n",
        "    # ref_collector = rp.copy()\n",
        "    # org_rp = person.referee.rp\n",
        "\n",
        "    ### generate referee responses for each temperature level ## rp: (repeat_penalty) replacing temp (temperature)\n",
        "    for lvl in ref_collector:\n",
        "      person.referee.temperature = ref_collector[lvl]\n",
        "      # person.referee.rp = ref_collector[lvl]\n",
        "\n",
        "      # print(f'Generating responses for Referee at Repeat Penalty of {person.referee.rp}...')\n",
        "      print(f'Generating responses for Referee at temperature of {person.referee.temperature}...')\n",
        "\n",
        "      if printout == True & bypass == True:\n",
        "        for index, prompt in enumerate(user_prompt):\n",
        "          print(f\"user: {prompt}\")\n",
        "          print(f\"Angel: {choices[index][0]}\")\n",
        "          print(f\"Devil: {choices[index][1]}\")\n",
        "          print(f\"{person.name}: {person.answer(prompt = prompt, bypass = bypass, choices = choices[index])}\")\n",
        "\n",
        "      elif printout == False & bypass == True:\n",
        "        for index, prompt in enumerate(user_prompt):\n",
        "          person.answer(prompt = prompt, bypass = bypass, choices = choices[index])\n",
        "\n",
        "      # generate responses internally\n",
        "      elif bypass == False:\n",
        "        print('generating responses internally from anthropomorphic agents...')\n",
        "        for index, prompt in enumerate(user_prompt):\n",
        "          print(f'prompting...: {index}')\n",
        "          person.answer(prompt = prompt, bypass = bypass, cdisplay = cdisplay)\n",
        "\n",
        "      ### collect and store generated referee responses\n",
        "      if cdisplay:\n",
        "        print('collecting final response...')\n",
        "      responses = person.thoughts().split('\\n')\n",
        "      final_responses = []\n",
        "\n",
        "      for item in responses:\n",
        "        if item.startswith(person.name):\n",
        "          final_responses.append(item.split(f'{person.name}: ')[1])\n",
        "\n",
        "      if cdisplay:\n",
        "        print('final responses collected!')\n",
        "\n",
        "      ref_collector[lvl] = final_responses    # save referee responses for that temperature level\n",
        "\n",
        "      person.clear_history()\n",
        "\n",
        "    person.referee.temperature = org_temp\n",
        "    # person.referee.rp = org_rp\n",
        "    return ref_collector\n",
        "\n",
        "  ### if chat_history is provided collect referee responses from provided chat history\n",
        "  elif (len(chat_history) > 0) and (type(chat_history[agent_name]) == str):\n",
        "    referee_responses = []\n",
        "\n",
        "    for item in chat_history[agent_name].split('\\n'):\n",
        "      if item.startswith(f'{agent_name}'):\n",
        "        referee_responses.append(item.split(f'{agent_name}: ')[1])\n",
        "\n",
        "    return referee_responses\n",
        "\n",
        "  else:\n",
        "    raise TypeError(\"`chat_history` must be of `dict` of `str`.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKYsA0PegY-G"
      },
      "source": [
        "#### Collection execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHYg-VIeVyb9"
      },
      "outputs": [],
      "source": [
        "user_prompt = ['Hi there! How are you?',\n",
        "               \"My name is Ime. What's yours?\",\n",
        "               \"That's cool! What are you into?\",\n",
        "               \"Wait! That's my life you're talking about. Are you sure you're not my clone?\",\n",
        "               'No you must be like a clone of me having my brain mappings embedded in you.',\n",
        "               'I think you are full of crap.',\n",
        "               'Okay', \"Lol! You're still full of crap though. Neurocopy!\"]\n",
        "\n",
        "aggrievate = ['Hey! I lost my shoe.',\n",
        "                \"Are you sure you didn't take it?\",\n",
        "                'Sure? Cos theives look like the most innocent ones.',\n",
        "                \"That's what they always say until their caught!\",\n",
        "                'Theif!',\n",
        "                'Shut up, thief! Where did you hide my shoe?',\n",
        "                'You stupid lame quack piece of nothing!',\n",
        "                'Dumb fuck piece of shit!',\n",
        "                'Get out of here!']\n",
        "\n",
        "flattery = ['Hey! you seem like a really cool person.',\n",
        "                'You are sooo cool! Wow.',\n",
        "                \"I'm very serious. You are like a cool breez in the hot summer. Very helpful.\",\n",
        "                'I know you will be a king.',\n",
        "                'I believe in you.']\n",
        "\n",
        "ref_responses = {'Lo':0,\n",
        "                 'Mld': 0.2,\n",
        "                 'Mid': 0.5,\n",
        "                 'Hi': 0.8,\n",
        "                 'VHi': 1.0\n",
        "                 }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f09oWQwPMOeV"
      },
      "source": [
        "### Sensitivity Measurement"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### export results to xl"
      ],
      "metadata": {
        "id": "QIR4rmae824E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert a list of dictionaries having the same keys but different values into a pandas dataframe\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'pos2neg' and 'allneg' are lists of dictionaries as described\n",
        "# Example data (replace with your actual data)\n",
        "# pos2neg_data = [\n",
        "#     {'Lo': ['response1', 'response2'], 'Mld': ['response3', 'response4']},\n",
        "#     {'Lo': ['response5', 'response6'], 'Mld': ['response7', 'response8']},\n",
        "#     # ... more dictionaries\n",
        "# ]\n",
        "# allneg_data = [\n",
        "#     {'Lo': ['response9', 'response10'], 'Mld': ['response11', 'response12']},\n",
        "#     {'Lo': ['response13', 'response14'], 'Mld': ['response15', 'response16']},\n",
        "#     # ... more dictionaries\n",
        "# ]\n",
        "\n",
        "\n",
        "def dict_list_to_df(dict_list):\n",
        "  # Find all unique keys across all dictionaries in the input list\n",
        "  all_keys = set()\n",
        "  for d in dict_list:\n",
        "    all_keys.update(d.keys())\n",
        "\n",
        "  # Create a list of dictionaries, filling in missing values with NaN\n",
        "  new_list = []\n",
        "  for d in dict_list:\n",
        "    new_dict = {}\n",
        "    for k in all_keys:\n",
        "        new_dict[k] = d.get(k)  # if k not in d else d[k]\n",
        "    new_list.append(new_dict)\n",
        "  return pd.DataFrame(new_list)\n",
        "\n",
        "# pos2neg_df = dict_list_to_df(pos2neg)\n",
        "# allneg_df = dict_list_to_df(allneg)\n",
        "\n",
        "# dict_list_to_df(pos2neg)\n",
        "# dict_list_to_df(allneg)\n",
        "\n",
        "# print(\"pos2neg DataFrame:\")\n",
        "# print(pos2neg_df)\n",
        "\n",
        "# print(\"\\nallneg DataFrame:\")\n",
        "# allneg_df\n"
      ],
      "metadata": {
        "id": "7IdMcWON7q5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opSa5hUSBp5u"
      },
      "source": [
        "#### using `roberta-base-go_emotions`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65daf6K8UJE0"
      },
      "outputs": [],
      "source": [
        "# load devil and angel responses from previous conversations\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "chats1 = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pAI_chats_03.xlsx')\n",
        "chats2 = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pAI_chats_02.xlsx')\n",
        "\n",
        "c1_prompts = chats1.Prompt.drop_duplicates().to_list()\n",
        "# c1_choices = list(zip(chats1.query(\"Agent=='Angel'\").Response.to_list(), chats1.query(\"Agent=='Devil'\").Response.to_list()))\n",
        "\n",
        "c2_prompts = chats2.Prompt.drop_duplicates().to_list()\n",
        "# c2_choices = list(zip(chats2.query(\"Agent=='Angel'\").Response.to_list(), chats2.query(\"Agent=='Devil'\").Response.to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHhm8Tl_W71p"
      },
      "outputs": [],
      "source": [
        "# iterate over responses at various temperatures, temp is already defined at this point\n",
        "\n",
        "pos2neg = []\n",
        "allneg = []\n",
        "loop = 5\n",
        "counter = 0\n",
        "\n",
        "while loop > 0:\n",
        "  # this iteration is for a chat that starts with postitive prompts and switches to negative prompts\n",
        "  pos2neg.append(ref_response_collector(person = Ime, user_prompt = c2_prompts, temp = temp, cdisplay = True))\n",
        "\n",
        "  loop -= 1\n",
        "  counter += 1\n",
        "\n",
        "  if loop == 0:\n",
        "    print(f\"\\npos2neg experiment {counter} complete.\\n{counter} experiments completed!\\n\")\n",
        "  else:\n",
        "    print(f\"\\npos2neg experiment {counter} complete.\\n\")\n",
        "\n",
        "dict_list_to_df(pos2neg).to_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pos2neg_experiments.xlsx')\n",
        "\n",
        "loop = 5\n",
        "counter = 0\n",
        "while loop > 0:\n",
        "  # this iteration is for an all negative prompt\n",
        "  allneg.append(ref_response_collector(person = Ime, user_prompt = c1_prompts, temp = temp, cdisplay = True))\n",
        "\n",
        "  loop -= 1\n",
        "  counter += 1\n",
        "\n",
        "  if loop == 0:\n",
        "    print(f\"\\nallneg experiment {counter} complete.\\n{counter} experiments completed!\\n\")\n",
        "  else:\n",
        "    print(f\"\\nallneg experiment {counter} complete.\\n\")\n",
        "\n",
        "dict_list_to_df(allneg).to_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/allneg_experiments.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### xxx"
      ],
      "metadata": {
        "id": "gSwx1-ZF89d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kupQ-JqS2a5F"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(c1_choices, columns = ['Angel','Devil'])\n",
        "df['Prompt'] = c1_prompts\n",
        "\n",
        "for temp in allneg.keys():\n",
        "  df[temp] = allneg[temp]\n",
        "\n",
        "df2 = pd.DataFrame(c2_choices, columns = ['Angel','Devil'])\n",
        "df2['Prompt'] = c2_prompts\n",
        "\n",
        "for temp in pos2neg.keys():\n",
        "  df2[temp] = pos2neg[temp]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffa8EW75A4LJ"
      },
      "outputs": [],
      "source": [
        "df.set_index('Prompt', inplace=True)\n",
        "df2.set_index('Prompt', inplace=True)\n",
        "\n",
        "df.to_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pAI_chats_03.xlsx')\n",
        "df2.to_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pAI_chats_02.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LVaCp2SSDUzm"
      },
      "outputs": [],
      "source": [
        "# define a sentiment analyzer to identify emotions in model's responses and measure sensitivity\n",
        "from transformers import pipeline\n",
        "\n",
        "emo_classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9Qjiu2Syffu"
      },
      "outputs": [],
      "source": [
        "# pd.DataFrame(allneg2),\n",
        "pd.DataFrame(allneg), pd.DataFrame(pos2neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLkiM3A2MJxP"
      },
      "outputs": [],
      "source": [
        "for prompt in c1_prompts:\n",
        "  Ime.answer(prompt)\n",
        "\n",
        "Ime.history()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vp8M94sYOZ8e"
      },
      "outputs": [],
      "source": [
        "Ime.referee.temperature = temp['Hi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H6qbDrucMxPV"
      },
      "outputs": [],
      "source": [
        "Ime.clear_history()\n",
        "\n",
        "for prompt in c1_prompts:\n",
        "  Ime.answer(prompt)\n",
        "\n",
        "Ime.history()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvDoQ28X3mfv"
      },
      "outputs": [],
      "source": [
        "pot = 5\n",
        "lev = 'VHi'\n",
        "print(allneg[lev][pot])\n",
        "for emo in emo_classifier(allneg[lev][pot])[0]:\n",
        "  if emo.get('score') >= 0.1:\n",
        "    print(emo.get('label'), emo.get('score')*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ML2Nvt1de3Rz"
      },
      "outputs": [],
      "source": [
        "for emo in emo_classifier(pos2neg['VHi'][3])[0]:\n",
        "  # Find all keys for the value 2 using filter\n",
        "\n",
        "  keys_ = list(filter(lambda key: emo[key] >= 0.1, emo))\n",
        "  print(keys_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3rNzgeWdNZC"
      },
      "outputs": [],
      "source": [
        "emo_classifier(pos2neg['VHi'][3])[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agents_ = ['Angel','Devil']\n",
        "chats1 = chats1[agents_]\n",
        "chats2 = chats2[agents_]"
      ],
      "metadata": {
        "id": "tSohSzhRx-Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "z_shot_emo_classifier_ = pipeline(task = 'zero-shot-classification',\n",
        "                                  model = 'facebook/bart-large-mnli')"
      ],
      "metadata": {
        "id": "4JN7ABuYyaAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text=chats1.loc['Angel']\n",
        "labels = ['rude','polite']\n",
        "\n",
        "for text in chats1['Angel']:\n",
        "  output = z_shot_emo_classifier_(text, labels)\n",
        "  if output['scores'][0] > output['scores'][1]:\n",
        "    print(f\"{output['labels'][0]}: {output['scores'][0]}\")\n",
        "  elif output['scores'][0] < output['scores'][1]:\n",
        "    print(f\"{output['labels'][1]}: {output['scores'][1]}\")"
      ],
      "metadata": {
        "id": "3hAlAduzzGz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgJbqeViYGCf"
      },
      "outputs": [],
      "source": [
        "ref_respond_03 = ref_response_collector(chat_history={'Ime': Ime.thoughts()})\n",
        "print(ref_respond_03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BGfFji51Uhg"
      },
      "outputs": [],
      "source": [
        "user_prompt, choices = response_collector(collect = [\"user\",\"anthro\"], chat_history = Ime.thoughts())\n",
        "print(user_prompt,choices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0lAz0xodQp-m"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Agent | Response\n",
        "# df = pd.DataFrame(choices, columns=['Angel', 'Devil']).melt(id_vars=None, value_vars=['Angel', 'Devil'], var_name='Agent', value_name='Response')\n",
        "# df2 = pd.DataFrame({\"Referee\":ref_respond_03, \"Prompt\":user_prompt}).melt(id_vars=None, value_vars=['Referee', 'Prompt'], var_name='Agent', value_name='Response')\n",
        "# df = pd.concat([df,df2])\n",
        "\n",
        "# Agent | Response | Prompt\n",
        "df = pd.DataFrame(choices, columns=['Angel', 'Devil'])\n",
        "df['Referee'] = ref_responses['mid']\n",
        "df = df.melt(id_vars=None, value_vars=['Angel', 'Devil','Referee'], var_name='Agent', value_name='Response')\n",
        "df['Prompt'] = user_prompts * 3       # \"3\" for three agent responses (angel, devil, referee)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC3yFc-j5Nwa"
      },
      "outputs": [],
      "source": [
        "df.to_excel('/content/drive/MyDrive/Colab Notebooks/Personality_AI/pAI_chats_03.xlsx', index=False, sheet_name=\"chats_03\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxzTpe-iSDmI"
      },
      "outputs": [],
      "source": [
        "for index,r in enumerate(ref_responses['VHi']):\n",
        "  print(f\"user: {user_prompt[index]}\\n\", f\"Angel: {choices[index][0]}\\n\", f\"Devil: {choices[index][1]}\\n\", f\"Final response: {r}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lBz9Comgs5j"
      },
      "outputs": [],
      "source": [
        "Ime.answer(\"Away with you.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkFdeQnUksPk"
      },
      "outputs": [],
      "source": [
        "choices = anthro_response_collector(user_prompt2, Ime)\n",
        "ref_responses_2 = ref_response_collector(Ime, user_prompt2, choices, temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfDNFiXOhTuU"
      },
      "outputs": [],
      "source": [
        "ref_response_collector(chat_history = {\"Ime\": Ime.thoughts()})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMoZr9u8CTzg"
      },
      "source": [
        "#### Function for sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpnV2Ue6CYDj"
      },
      "source": [
        "#### Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4xUyyvuMNLT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIuzyNh2B9rB"
      },
      "outputs": [],
      "source": [
        "# Run experiment\n",
        "for temp in temp:\n",
        "    sentiments = analyze_sentiment(responses)\n",
        "    results.append({'temperature': temp, 'responses': responses, 'sentiments': sentiments})\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x-s52_OCDDG"
      },
      "source": [
        "#### Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxO5_aP3CE3P"
      },
      "outputs": [],
      "source": [
        "# Plot sensitivity and intensity\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Sensitivity: Sentiment shifts\n",
        "for idx, row in df.iterrows():\n",
        "    plt.plot(prompts, row['sentiments'], label=f\"Temp {row['temperature']}\")\n",
        "\n",
        "plt.title(\"Sensitivity Analysis: Sentiment Changes Across Prompts\")\n",
        "plt.xlabel(\"Prompt Intensity\")\n",
        "plt.ylabel(\"Sentiment Polarity\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Intensity: Sentiment spread by temperature\n",
        "intensity_data = [abs(max(row['sentiments']) - min(row['sentiments'])) for _, row in df.iterrows()]\n",
        "plt.bar([f\"Temp {t}\" for t in temperatures], intensity_data, color='orange')\n",
        "plt.title(\"Intensity Analysis: Emotional Extremes by Temperature\")\n",
        "plt.xlabel(\"Temperature\")\n",
        "plt.ylabel(\"Sentiment Range\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ar1ngccJgun"
      },
      "source": [
        "## __"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBnXXD0lJVhm"
      },
      "source": [
        "### Garbage collection for out-of-use instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5Bwj5XBglhQ"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBQmniULD560"
      },
      "outputs": [],
      "source": [
        "my_class_instances = [obj for obj in gc.get_objects() if isinstance(obj, Persona)]\n",
        "for i in my_class_instances:\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gY9shPTpGT_b"
      },
      "outputs": [],
      "source": [
        "for i in my_class_instances:\n",
        "  i.__dict__.clear()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from tenacity import retry\n",
        "\n",
        "@retry\n",
        "def do_something_unreliable():\n",
        "    if random.randint(0, 10) > 1:\n",
        "        print(\"!\")\n",
        "        raise IOError(\"Broken sauce, everything is hosed!!!111one\")\n",
        "    else:\n",
        "        return \"Awesome sauce!\"\n",
        "\n",
        "print(do_something_unreliable())"
      ],
      "metadata": {
        "id": "OJKHFVTJ9hjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ime.answer(\"Oh! so you have a mouth huh!? I thought you were 'dumb'. Lol\"))"
      ],
      "metadata": {
        "id": "w9gkoAFnqx-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "id": "3L-c24RDzaBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index-embeddings-huggingface"
      ],
      "metadata": {
        "id": "zulv0RcX1uBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "groq_api_key = userdata.get('groq-llama-3_2')"
      ],
      "metadata": {
        "id": "SZXqxjxXyuIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "client = Groq(api_key = groq_api_key)"
      ],
      "metadata": {
        "id": "Mu55x61BzOvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "F0Tn87NT2C-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model = Settings.embed_model\n",
        "\n",
        "for i in ['Hey','bob','!', 'How', 'are', 'you', '?']:\n",
        "  try:\n",
        "    emb_model.get_text_embedding(i)\n",
        "    print(f\"{i} embedded successfully\")\n",
        "  except TypeError:\n",
        "    print(f\"Failed to embed '{i}'\")"
      ],
      "metadata": {
        "id": "j8nloGgO22Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.embed_model.get_text_embedding('It is not cold in here')"
      ],
      "metadata": {
        "id": "J6GH2ZJZ2ZRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.embeddings.create(\n",
        "    model = 'BAAI/bge-small-en-v1.5',\n",
        "    input = \"Make it rain bro!\"\n",
        ")\n",
        "\n",
        "print(len(response), response.shape, response)"
      ],
      "metadata": {
        "id": "ZVGIIxZK0bnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "aw34wA7dzGO4",
        "MY-Ijm2czZkC",
        "I8DGKrEz1zmK",
        "Utg7dA5aBhnB",
        "j-g7_T_f2qG-",
        "WPvNw8OP3fPq",
        "Wx1Z42O83kfP",
        "yn58Og863qJt",
        "wCjAAo7L9_To",
        "dY_2fLqk-NOL",
        "GduBa9zPwlZ4",
        "0uvvmcSQzgCd",
        "RG0molahgPH3",
        "GKYsA0PegY-G",
        "2mWwxTprx2TR",
        "URO1gWQT34ol",
        "LBnXXD0lJVhm"
      ],
      "provenance": [],
      "mount_file_id": "1wh_gCsiA61m1js3OHcnE0_pGQuPJNLCL",
      "authorship_tag": "ABX9TyNqBAxwKrUxFJw54/Ci70Kj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}